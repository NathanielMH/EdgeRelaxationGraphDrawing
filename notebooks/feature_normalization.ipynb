{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46b6915-c5ef-4764-8c16-5071a4b07f91",
   "metadata": {},
   "source": [
    "# Normalization of edge features for intergraph comparation of the effect of edge relaxation\n",
    "When considering edge features in a graph such as $\\Delta ec = ec_{old} - ec_{new}$, one should be careful when using this parameter to compare different graphs, as for this particular example, if one graph has 1000 edge crossings and relaxing a certain edge removes one of them, we can consider it played little to no effect, however if another graph has 10 crossings and we remove one, that is a bettering of 10% compared ti the 0.1% seen before. And the fact is that the parameter $\\Delta e_c$ conveys the same information in both cases.\n",
    "We will therefore see a number of possible normalization processes for some of the edge attributes that we are dealing with.\n",
    "\n",
    "## Edge crossings\n",
    "Edge crossings are an inherent characteristic to a graph's drawing. They range from 0 to $\\frac{(|E|-1)\\cdot|E|}{2}$, and therefore the different in edge crossings ranges from - $\\frac{(|E|-1)\\cdot|E|}{2}$ to $\\frac{(|E|-1)\\cdot|E|}{2}$. It follows that a possible normalization procedure would be to divide $\\delta e_c$ by $\\frac{(|E|-1)\\cdot|E|}{2}$, so as to get a value between -1 and 1.\n",
    "Another possibility we can look at, which takes into account the graph's complexity is the reduction percentage, that we can define as $\\frac{(ec_{old}-ec_{new})}{ec_{old}}$ which is close to 1 when we reduce the number of crossings significantly, 0 when we don't change it and negative when we worsen it. It's interesting to consider this variant as it allows for a qualitative improvement on the graph, not only numerical: we take into account how much has the graph gotten better, not only by how much it has changed.\n",
    "\n",
    "## Expansion factor\n",
    "This is a measure of disturbance of the drawing caused by he relaxation of an edge. It measures the distance between nodes before relaxing and nodes after relaxing and executing a couple more iterations of your favorite graph drawing algorithm (we will use Kamada Kawai). However, setting it to $\\sum_{i=0}^{|V|}||x^{i}-f(x^{i})||$ allows bigger graphs with more nodes to have this parameter unusually high.\n",
    "Therefore, we can consider normalizing in terms of the number of nodes: $\\sum_{i=0}^{|V|}\\frac{||x^{i}-f(x^{i})||}{|V|}$.\n",
    "This way we have the disturbance per node and we don't discriminate in terms of the number of nodes of a graph.\n",
    "\n",
    "## Gradient difference\n",
    "We also measure the difference between the gradients of the Kamada Kawai before relaxing the edge and after. Note that because the non linear optimization looks for local optima, the gradient of the KK will possibly be zero after the execution and we measure the norm of the gradient after relaxing an edge. (Recomputing d(i,j)).\n",
    "Therefore, our parameter could be $||\\nabla(KK_{after}) - \\nabla(KK_{before})||$. \n",
    "\n",
    "## Max degree of connecting nodes\n",
    "This feature obviously increases as the size of our graph increases, and therefore it is a good idea to normalize it by dividing it by the total amount of nodes: $max_{v_i \\in N_u}\\frac{(deg(v_i)}{|V|}$\n",
    "\n",
    "## Sum of degrees of connecting nodes\n",
    "Similarly as for the max degree of connecting nodes, this feature increases with the size of our graph, and we therefore normalize it by dividing by the total amount of nodes: $\\sum_{v_i \\in N_u}\\frac{deg(v_i)}{|V|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8170ad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.888175489579267\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def expansion_factor_norm(layout1: np.array, layout2: np.array, nnodes:int) -> float:\n",
    "    \"\"\"\n",
    "    Computes the normalized expansion factor.\n",
    "\n",
    "    Args: \n",
    "    - layout1 (np.array) : layout of graph before relaxing the edge, nnodes*k array where k is the dimensionality of the drawing\n",
    "    - layout2 (np.array) : layout of graph after relaxation of the edge and iterations of Kamada Kawai, nnodes*k array\n",
    "    - nnodes (int) : Number of node of the graph\n",
    "\n",
    "    Returns:\n",
    "    - expansion factor normalized by nnodes (float)\n",
    "    \"\"\"\n",
    "    return np.sum([np.linalg.norm(layout1[i]-layout2[i]) for i in range(nnodes)])/nnodes\n",
    "\n",
    "l1 = np.array([[3.12,7.23],[1.1,8.33],[3.43,4.3]])\n",
    "l2 = np.array([[1,0],[1,2],[7,3]])\n",
    "print(expansion_factor_norm(l1,l2,3))\n",
    "\n",
    "# IMPORTANT: en graph train, estem per la diferència de estrés i la reducció del nombre de crossings fent un dibuix totalment nou.\n",
    "# Per lògica i utilitat hauríem de partir del dibuix que ja tenim per calcular entre altres coses la diferència de gradient i el factor d'expansió\n",
    "# Que tenen a veure en l'evolució dinàmica del dibuix, i per tant s'hauria de iterar sobre el mateix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b6e042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def sum_neighbour_degrees_norm(G: nx.Graph, e) -> float:\n",
    "    \"\"\"\n",
    "    Computes the sum of degrees of edges connecting the edge normalized by the graph size (nnodes).\n",
    "\n",
    "    Args:\n",
    "    - G (nx.graph) : graph\n",
    "    - e (edge) : edge \n",
    "\n",
    "    Returns:\n",
    "    - sum of neighbour nodes normalized (float)\n",
    "    \"\"\"\n",
    "    return (e[0] + e[1])/len(G.nodes)\n",
    "\n",
    "def max_neighbour_degrees_norm(G: nx.Graph, e) -> float:\n",
    "    \"\"\"\n",
    "    Computes the max of degrees of edges connecting the edge normalized by the graph size (nnodes).\n",
    "\n",
    "    Args:\n",
    "    - G (nx.graph) : graph\n",
    "    - e (edge) : edge \n",
    "\n",
    "    Returns:\n",
    "    - max of neighbour nodes normalized (float)\n",
    "    \"\"\"\n",
    "    return max(e[0],e[1])/len(G.nodes)\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(1,2),(1,3),(3,4),(7,3),(9,0)])\n",
    "sum_neighbour_degrees_norm(G,(1,2))\n",
    "max_neighbour_degrees_norm(G,(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d143fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.87397426  2.62758654 -2.94801656  2.39279414  1.0740423  -5.02038067]\n"
     ]
    }
   ],
   "source": [
    "def gradient_kamada_kawai(layout:np.array, d: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Computes the gradient of the Kamada Kawai function and evaluates it at the given 2D layout.\n",
    "\n",
    "    Args:\n",
    "    - layout (np.array) : layout to evaluate gradient at\n",
    "    - d (np.array) : symmetric matrix of size nnodes*nnodes with d_ij = d(i,j) ideal distance from i to j\n",
    "\n",
    "    Returns:\n",
    "    - gradient of the kamada kawai evaluated at the layout as a numpy array of the form [dx_11, dx_12, dx_21, dx_22, ...]\n",
    "    \"\"\"\n",
    "\n",
    "    grad = np.array([0 for i in range(2*len(layout))], dtype=np.float64)\n",
    "    for i in range(len(layout)):\n",
    "        dx = np.sum([2*(layout[i][0]-layout[j][0])/d[i][j]*(1/d[i][j]-1/np.linalg.norm(layout[i,:]-layout[j,:])) if j!=i else 0. for j in range(len(layout))])\n",
    "        dy = np.sum([2*(layout[i][1]-layout[j][1])/d[i][j]*(1/d[i][j]-1/np.linalg.norm(layout[i,:]-layout[j,:])) if j!=i else 0. for j in range(len(layout))])\n",
    "        grad[2*i] = dx\n",
    "        grad[2*i+1] = dy\n",
    "    return grad\n",
    "\n",
    "d = distance_matrix(G)\n",
    "\n",
    "g = gradient_kamada_kawai(l1,d)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2cd2430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.154721862658083\n",
      "2.7647685166364226\n"
     ]
    }
   ],
   "source": [
    "def distance_matrix(G: nx.Graph) -> np.array:\n",
    "    \"\"\"\n",
    "    Returns the distance matrix of the graph, defined by d[i][j] = shortest path length between node i and j.\n",
    "\n",
    "    Args:\n",
    "    - G (nx.graph): graph\n",
    "\n",
    "    Returns:\n",
    "    - distance matrix as a numpy array\n",
    "\n",
    "    Note: Heavily inspired by nx source code.\n",
    "    \"\"\"\n",
    "    nNodes = len(G)\n",
    "    dist = dict(nx.shortest_path_length(G, weight=None))\n",
    "    dist_mtx = 1e6 * np.ones((nNodes, nNodes))\n",
    "    for row, nr in enumerate(G):\n",
    "        if nr not in dist:\n",
    "            continue\n",
    "        rdist = dist[nr]\n",
    "        for col, nc in enumerate(G):\n",
    "            if nc not in rdist:\n",
    "                continue\n",
    "            dist_mtx[row][col] = rdist[nc]\n",
    "    return dist_mtx\n",
    "\n",
    "d = distance_matrix(G)\n",
    "dict_layout = nx.kamada_kawai_layout(G)\n",
    "arr_layout = []\n",
    "for node in dict_layout.keys():\n",
    "    arr_layout.append(dict_layout[node])\n",
    "arr_layout = np.array(arr_layout)\n",
    "print(np.linalg.norm(g))\n",
    "g = gradient_kamada_kawai(arr_layout,distance_matrix(G))\n",
    "print(np.linalg.norm(g))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
