{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f46b6915-c5ef-4764-8c16-5071a4b07f91",
   "metadata": {},
   "source": [
    "# Normalization of edge features for intergraph comparation of the effect of edge relaxation\n",
    "When considering edge features in a graph such as $\\Delta ec = ec_{old} - ec_{new}$, one should be careful when using this parameter to compare different graphs, as for this particular example, if one graph has 1000 edge crossings and relaxing a certain edge removes one of them, we can consider it played little to no effect, however if another graph has 10 crossings and we remove one, that is a bettering of 10% compared ti the 0.1% seen before. And the fact is that the parameter $\\Delta e_c$ conveys the same information in both cases.\n",
    "We will therefore see a number of possible normalization processes for some of the edge attributes that we are dealing with.\n",
    "\n",
    "## Edge crossings\n",
    "Edge crossings are an inherent characteristic to a graph's drawing. They range from 0 to $\\frac{(|E|-1)\\cdot|E|}{2}$, and therefore the different in edge crossings ranges from - $\\frac{(|E|-1)\\cdot|E|}{2}$ to $\\frac{(|E|-1)\\cdot|E|}{2}$. It follows that a possible normalization procedure would be to divide $\\delta e_c$ by $\\frac{(|E|-1)\\cdot|E|}{2}$, so as to get a value between -1 and 1.\n",
    "Another possibility we can look at, which takes into account the graph's complexity is the reduction percentage, that we can define as $\\frac{(ec_{old}-ec_{new})}{ec_{old}}$ which is close to 1 when we reduce the number of crossings significantly, 0 when we don't change it and negative when we worsen it. It's interesting to consider this variant as it allows for a qualitative improvement on the graph, not only numerical: we take into account how much has the graph gotten better, not only by how much it has changed.\n",
    "\n",
    "## Expansion factor\n",
    "This is a measure of disturbance of the drawing caused by he relaxation of an edge. It measures the distance between nodes before relaxing and nodes after relaxing and executing a couple more iterations of your favorite graph drawing algorithm (we will use Kamada Kawai). However, setting it to $\\sum_{i=0}^{|V|}||x^{i}-f(x^{i})||$ allows bigger graphs with more nodes to have this parameter unusually high.\n",
    "Therefore, we can consider normalizing in terms of the number of nodes: $\\sum_{i=0}^{|V|}\\frac{||x^{i}-f(x^{i})||}{|V|}$.\n",
    "This way we have the disturbance per node and we don't discriminate in terms of the number of nodes of a graph.\n",
    "\n",
    "## Gradient difference\n",
    "We also measure the difference between the gradients of the Kamada Kawai before relaxing the edge and after. Note that because the non linear optimization looks for local optima, the gradient of the KK will possibly be zero after the execution and we measure the norm of the gradient after relaxing an edge. (Recomputing d(i,j)).\n",
    "Therefore, our parameter could be $||\\nabla(KK_{after}) - \\nabla(KK_{before})||$. \n",
    "\n",
    "## Max degree of connecting nodes\n",
    "This feature obviously increases as the size of our graph increases, and therefore it is a good idea to normalize it by dividing it by the total amount of nodes: $max_{v_i \\in N_u}\\frac{(deg(v_i)}{|V|}$\n",
    "\n",
    "## Sum of degrees of connecting nodes\n",
    "Similarly as for the max degree of connecting nodes, this feature increases with the size of our graph, and we therefore normalize it by dividing by the total amount of nodes: $\\sum_{v_i \\in N_u}\\frac{deg(v_i)}{|V|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8170ad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.888175489579267\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def expansion_factor_norm(layout1: np.array, layout2: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Computes the normalized expansion factor.\n",
    "\n",
    "    Args: \n",
    "    - layout1 (np.array) : layout of graph before relaxing the edge, nnodes*k array where k is the dimensionality of the drawing\n",
    "    - layout2 (np.array) : layout of graph after relaxation of the edge and iterations of Kamada Kawai, nnodes*k array\n",
    "    - nnodes (int) : Number of node of the graph\n",
    "\n",
    "    Returns:\n",
    "    - expansion factor normalized by nnodes (float)\n",
    "    \"\"\"\n",
    "    nnodes = len(layout1)\n",
    "    return np.sum([np.linalg.norm(layout1[i]-layout2[i]) for i in range(nnodes)])/nnodes\n",
    "\n",
    "l1 = np.array([[3.12,7.23],[1.1,8.33],[3.43,4.3]])\n",
    "l2 = np.array([[1,0],[1,2],[7,3]])\n",
    "print(expansion_factor_norm(l1,l2,3))\n",
    "\n",
    "# IMPORTANT: en graph train, estem per la diferència de estrés i la reducció del nombre de crossings fent un dibuix totalment nou.\n",
    "# Per lògica i utilitat hauríem de partir del dibuix que ja tenim per calcular entre altres coses la diferència de gradient i el factor d'expansió\n",
    "# Que tenen a veure en l'evolució dinàmica del dibuix, i per tant s'hauria de iterar sobre el mateix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b6e042f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def sum_neighbour_degrees_norm(G: nx.Graph, e) -> float:\n",
    "    \"\"\"\n",
    "    Computes the sum of degrees of edges connecting the edge normalized by the graph size (nnodes).\n",
    "\n",
    "    Args:\n",
    "    - G (nx.graph) : graph\n",
    "    - e (edge) : edge \n",
    "\n",
    "    Returns:\n",
    "    - sum of neighbour nodes normalized (float)\n",
    "    \"\"\"\n",
    "    u,v = e\n",
    "    return (G.degree[u]+G.degree[v])/len(G.nodes)\n",
    "\n",
    "def max_neighbour_degrees_norm(G: nx.Graph, e) -> float:\n",
    "    \"\"\"\n",
    "    Computes the max of degrees of edges connecting the edge normalized by the graph size (nnodes).\n",
    "\n",
    "    Args:\n",
    "    - G (nx.graph) : graph\n",
    "    - e (edge) : edge \n",
    "\n",
    "    Returns:\n",
    "    - max of neighbour nodes normalized (float)\n",
    "    \"\"\"\n",
    "    u,v = e\n",
    "    return max(G.degree[u],G.degree[v])/len(G.nodes)\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(1,2),(1,3),(3,4),(7,3),(9,0)])\n",
    "sum_neighbour_degrees_norm(G,(1,2))\n",
    "max_neighbour_degrees_norm(G,(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d143fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.87397426  2.62758654 -2.94801656  2.39279414  1.0740423  -5.02038067]\n"
     ]
    }
   ],
   "source": [
    "def gradient_kamada_kawai(layout:np.array, d: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Computes the gradient of the Kamada Kawai function and evaluates it at the given 2D layout.\n",
    "\n",
    "    Args:\n",
    "    - layout (np.array) : layout to evaluate gradient at\n",
    "    - d (np.array) : symmetric matrix of size nnodes*nnodes with d_ij = d(i,j) ideal distance from i to j\n",
    "\n",
    "    Returns:\n",
    "    - gradient of the kamada kawai evaluated at the layout as a numpy array of the form [dx_11, dx_12, dx_21, dx_22, ...]\n",
    "    \"\"\"\n",
    "\n",
    "    grad = np.array([0 for i in range(2*len(layout))], dtype=np.float64)\n",
    "    for i in range(len(layout)):\n",
    "        dx = np.sum([2*(layout[i][0]-layout[j][0])/d[i][j]*(1/d[i][j]-1/np.linalg.norm(layout[i,:]-layout[j,:])) if j!=i else 0. for j in range(len(layout))])\n",
    "        dy = np.sum([2*(layout[i][1]-layout[j][1])/d[i][j]*(1/d[i][j]-1/np.linalg.norm(layout[i,:]-layout[j,:])) if j!=i else 0. for j in range(len(layout))])\n",
    "        grad[2*i] = dx\n",
    "        grad[2*i+1] = dy\n",
    "    return grad\n",
    "\n",
    "d = distance_matrix(G)\n",
    "\n",
    "g = gradient_kamada_kawai(l1,d)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2cd2430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.154721862658083\n",
      "2.7647685166364226\n"
     ]
    }
   ],
   "source": [
    "def distance_matrix(G: nx.Graph) -> np.array:\n",
    "    \"\"\"\n",
    "    Returns the distance matrix of the graph, defined by d[i][j] = shortest path length between node i and j.\n",
    "\n",
    "    Args:\n",
    "    - G (nx.graph): graph\n",
    "\n",
    "    Returns:\n",
    "    - distance matrix as a numpy array\n",
    "\n",
    "    Note: Heavily inspired by nx source code.\n",
    "    \"\"\"\n",
    "    nNodes = len(G)\n",
    "    dist = dict(nx.shortest_path_length(G, weight=None))\n",
    "    dist_mtx = 1e6 * np.ones((nNodes, nNodes))\n",
    "    for row, nr in enumerate(G):\n",
    "        if nr not in dist:\n",
    "            continue\n",
    "        rdist = dist[nr]\n",
    "        for col, nc in enumerate(G):\n",
    "            if nc not in rdist:\n",
    "                continue\n",
    "            dist_mtx[row][col] = rdist[nc]\n",
    "    return dist_mtx\n",
    "\n",
    "d = distance_matrix(G)\n",
    "dict_layout = nx.kamada_kawai_layout(G)\n",
    "arr_layout = []\n",
    "for node in dict_layout.keys():\n",
    "    arr_layout.append(dict_layout[node])\n",
    "arr_layout = np.array(arr_layout)\n",
    "print(np.linalg.norm(g))\n",
    "g = gradient_kamada_kawai(arr_layout,distance_matrix(G))\n",
    "print(np.linalg.norm(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b19a5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_crossings_norm(diff_cross: int, nedges:int) -> float:\n",
    "    \"\"\" \n",
    "    Computes normalized edge crossings by dividing the difference by the total amount of possible crossings.\n",
    "\n",
    "    Args:\n",
    "    - diff_cross (int) : difference in crossings between drawings\n",
    "    - nedges (int) : number of edges of the graph\n",
    "\n",
    "    Returns:\n",
    "    - normalized edge crossing difference \n",
    "    \"\"\"\n",
    "    if nedges == 1: return 0.\n",
    "    return 2*diff_cross/(nedges*(nedges-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c8040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def nodes_dict_to_array(dict_layout:dict) -> np.array:\n",
    "    \"\"\" \n",
    "    Converts nodes dict to array\n",
    "\n",
    "    Args:\n",
    "    - dict_layout (dict[node,np.array]): position of nodes in drawing as dict\n",
    "\n",
    "    Returns:\n",
    "    - np.array of coordinates of graph drawing\n",
    "    \"\"\"\n",
    "    arr_layout = []\n",
    "    for node in dict_layout.keys():\n",
    "        arr_layout.append(dict_layout[node])\n",
    "    return np.array(arr_layout)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dab69bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def j_node_centrality(G:nx.Graph, layout: np.array, numIterations:int = 1000, node = None) -> np.array:\n",
    "    \"\"\"\n",
    "    Returns an array of node J-centralities, computed iteratively\n",
    "\n",
    "    Args:\n",
    "    - G (nx.Graph): graph from which we wish to draw the J-centralities\n",
    "    - layout (np.array float): matrix with coordinates of each node as columns\n",
    "    - numIterations (int): number of iterations to compute centralities\n",
    "    \n",
    "    Returns:\n",
    "    - np.array of float as node J-centralities\n",
    "    \"\"\"\n",
    "    nNodes = len(G.nodes)\n",
    "    idx_to_node = {idx:node for idx, node in enumerate(G.nodes)}\n",
    "    node_to_idx = {node:idx for idx, node in enumerate(G.nodes)}\n",
    "    degree = nx.degree(G)\n",
    "    L = np.ones((nNodes))\n",
    "    for it in range(numIterations):\n",
    "        order_traversal = np.random.permutation(nNodes)\n",
    "        # to avoid prioritizing nodes or paths based on sequential traversal\n",
    "        for i in order_traversal:\n",
    "            L[i] = np.sum([L[j]*np.linalg.norm(layout[i]-layout[j]) for j in range(nNodes)])/degree[idx_to_node[i]]\n",
    "        sumCentralities = np.sum(L)\n",
    "        L /= sumCentralities\n",
    "    \n",
    "    # Normalize\n",
    "    \n",
    "    if node is not None: return nNodes*L[node_to_idx[node]]\n",
    "    return nNodes*L    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af1c33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_j_node_centrality(G: nx.Graph, layout:np.array, e, numIterations:int =1000) -> float:\n",
    "    \"\"\"\n",
    "    Computes maximum of j_node_centralities of connecting nodes\n",
    "\n",
    "    Args:\n",
    "    - G (nx.Graph): graph\n",
    "    - layout (np.array): layout of the drawing of G\n",
    "    - e (edge): edge for which we which to compute max_j_node_centralities\n",
    "    - numIterations (int, optional): _description_. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "    - float: max of the centralities of the nodes that the edge connects\n",
    "    \n",
    "    \"\"\"\n",
    "    u,v = e\n",
    "    return max(j_node_centrality(G,layout,numIterations,u),j_node_centrality(G,layout,numIterations,v))\n",
    "\n",
    "def sum_j_node_centrality(G: nx.Graph, layout:np.array, e, numIterations:int =1000) -> float:\n",
    "    \"\"\"\n",
    "    Computes sum of j_node_centralities of connecting nodes\n",
    "\n",
    "    Args:\n",
    "    - G (nx.Graph): graph\n",
    "    - layout (np.array): layout of the drawing of G\n",
    "    - e (edge): edge for which we which to compute max_j_node_centralities\n",
    "    - numIterations (int, optional): _description_. Defaults to 1000.\n",
    "\n",
    "    Returns:\n",
    "    - float: sum of the centralities of the nodes that the edge connects\n",
    "    \n",
    "    \"\"\"\n",
    "    u,v = e\n",
    "    return j_node_centrality(G,layout,numIterations,u)+j_node_centrality(G,layout,numIterations,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be2640e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'f': 4}\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'f': 4}\n",
      "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'f': 4}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.926025140904622"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([('a','b'),('b','c'),('d','f')])\n",
    "j_node_centrality(G,nodes_dict_to_array(nx.kamada_kawai_layout(G)))\n",
    "max_j_node_centrality(G,nodes_dict_to_array(nx.kamada_kawai_layout(G)),list(G.edges)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04955802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1313797864771211\n",
      "0.6017535646233393\n",
      "2.425362657142753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2288\\1931168808.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mpos1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkamada_kawai_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_copy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mpos1_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_dict_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_j_node_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_copy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos1_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\natha\\OneDrive\\Documentos\\GitHub\\EdgeRelaxationGraphDrawing\\src\\graph_utils.py\u001b[0m in \u001b[0;36mmax_j_node_centrality\u001b[1;34m(G, layout, e, numIterations)\u001b[0m\n\u001b[0;32m    712\u001b[0m     \"\"\"\n\u001b[0;32m    713\u001b[0m     \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj_node_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumIterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj_node_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumIterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msum_j_node_centrality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumIterations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\OneDrive\\Documentos\\GitHub\\EdgeRelaxationGraphDrawing\\src\\graph_utils.py\u001b[0m in \u001b[0;36mj_node_centrality\u001b[1;34m(G, layout, numIterations, node)\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# to avoid prioritizing nodes or paths based on sequential traversal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0morder_traversal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m             \u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnNodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_to_node\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m         \u001b[0msumCentralities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0mL\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0msumCentralities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\OneDrive\\Documentos\\GitHub\\EdgeRelaxationGraphDrawing\\src\\graph_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# to avoid prioritizing nodes or paths based on sequential traversal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0morder_traversal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m             \u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnNodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_to_node\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m         \u001b[0msumCentralities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0mL\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0msumCentralities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\natha\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2528\u001b[0m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2530\u001b[1;33m                 \u001b[0msqnorm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2531\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from src.graph_dataset import GraphDataset\n",
    "from src.graph_parser import parseGraphmlFile\n",
    "from src.graph_utils import stress, total_stress, num_crossings, mean_edge_length, nodes_dict_to_array, distance_matrix\n",
    "from src.graph_utils import gradient_kamada_kawai, max_neighbour_degrees_norm, sum_neighbour_degrees_norm, expansion_factor_norm, edge_crossings_norm\n",
    "from src.graph_utils import max_j_node_centrality, sum_j_node_centrality, j_node_centrality\n",
    "\n",
    "def read_list_of_graphs(dir_name,ext):\n",
    "    list_graphs = [parseGraphmlFile(dir_name+f,weighted=False,directed=False) for f in os.listdir(dir_name) if f.endswith('.' + ext)]\n",
    "    return list_graphs\n",
    "\n",
    "n = 0\n",
    "m = 1\n",
    "draw_f = lambda g: nx.kamada_kawai_layout(g, pos=nx.spectral_layout(g))\n",
    "benchmarks = ['random-dag', 'rome', 'north']\n",
    "\n",
    "data = []\n",
    "for bench in benchmarks:\n",
    "    list_graphs = read_list_of_graphs(f'../data/{bench}/','graphml')\n",
    "    for idx_graph, graph in tqdm(list(enumerate(list_graphs[n:m]))):\n",
    "\n",
    "        # Run Spectral +  Kamada-Kawai\n",
    "        pos0 = draw_f(graph)\n",
    "        for idx_edge, e in enumerate(graph.edges):\n",
    "            n1, n2 = e\n",
    "            \n",
    "            # New position removing edge\n",
    "            graph_copy = graph.copy()\n",
    "            graph_copy.remove_edges_from([e])\n",
    "            pos1 = nx.kamada_kawai_layout(graph_copy,pos=pos0)\n",
    "            pos1_arr = nodes_dict_to_array(pos1)\n",
    "            print(max_j_node_centrality(graph_copy,pos1_arr,e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6716dbedf63cc3cc3454830c6e7cfdb12d0aa2e0dca19a8f02decd88c98998a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
